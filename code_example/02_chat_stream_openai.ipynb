{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d694561f-35f3-4dc0-9f53-9ee3ff0c2d30",
   "metadata": {},
   "source": [
    "# 游눫 Streaming de respuestas: OpenAI\n",
    "\n",
    "Cuando trabajamos con LLMs, a veces queremos que el modelo genere texto en tiempo real, caracter por caracter o frase por frase. A esto se le llama **respuesta en streaming**.\n",
    "\n",
    "La API de **OpenAI** permite hacer streaming de respuestas mediante un bucle que consume eventos parciales. Puedes ver un ejemplo pr치ctico aqu칤:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f92b82f1-1f89-48e3-8bc8-4827688548c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "춰Perfecto! Aqu칤 tienes c칩mo quedar칤a tu agenda para hoy:\n",
      "\n",
      "---\n",
      "\n",
      "### **Agenda del d칤a**\n",
      "1. **Reuni칩n 1:**\n",
      "   - **Hora:** 7:00 AM - 8:00 AM\n",
      "   - **Estado:** Confirmada.\n",
      "\n",
      "2. **Reuni칩n 2:**\n",
      "   - **Hora:** 10:00 AM - 12:00 PM\n",
      "   - **Estado:** Pendiente de confirmaci칩n por correo. Si no llega el correo, se cancela.\n",
      "\n",
      "3. **Reuni칩n 3:**\n",
      "   - **Hora:** 2:00 PM - 4:00 PM\n",
      "   - **Estado:** Confirmada.\n",
      "\n",
      "---\n",
      "\n",
      "**Seguimiento:**\n",
      "- Revisa tu correo antes de las 10:00 AM para confirmar si la reuni칩n de las 10:00 AM sigue en pie.\n",
      "- Si no llega el correo de confirmaci칩n, puedes usar ese tiempo para otras tareas o descansos.\n",
      "\n",
      "쯅ecesitas ayuda con recordatorios o algo m치s? 游땕"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "client = openai.OpenAI(base_url=\"https://models.inference.ai.azure.com\", api_key=os.environ[\"GITHUB_API_KEY\"])\n",
    "MODEL_NAME = os.getenv(\"GITHUB_MODEL\", \"gpt-4o\")\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=MODEL_NAME,\n",
    "    temperature=0.7,\n",
    "    max_tokens=500,\n",
    "    n=1,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Eres un asistente virtual para organizar mi dia\"},\n",
    "        {\"role\": \"user\", \"content\": \"tengo 3 reuniones hoy, agendalas 7am-8am 10am-12am y 2pm-4pm. si no llega el correo de confirmacion la de las 10am se cancela\"},\n",
    "    ],\n",
    "    stream=True,\n",
    ")\n",
    "\n",
    "for event in completion:\n",
    "    if event.choices:\n",
    "        content = event.choices[0].delta.content\n",
    "        if content:\n",
    "            print(content, end=\"\", flush=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
