{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d0367c1-bc4b-4273-9a7a-12f07b32caa2",
   "metadata": {},
   "source": [
    "# üîó Llamadas encadenadas con Gemini\n",
    "\n",
    "Al igual que con la API de OpenAI, tambi√©n es posible implementar un flujo de llamadas encadenadas (*chained calls*) con Gemini. En este ejemplo, se sigue un patr√≥n de tres pasos para mejorar progresivamente un texto generado por el modelo:\n",
    "\n",
    "1. **‚úçÔ∏è Generaci√≥n inicial**: Se le pide al modelo que explique c√≥mo funcionan los LLM en un solo p√°rrafo.  \n",
    "2. **üßê Revisi√≥n editorial**: Luego se le pide que act√∫e como editor y d√© retroalimentaci√≥n detallada sobre claridad, coherencia y cautivaci√≥n.  \n",
    "3. **üõ† Revisi√≥n final**: Finalmente, el modelo reescribe el contenido original usando los comentarios como gu√≠a, manteni√©ndose en un solo p√°rrafo.\n",
    "\n",
    "Este patr√≥n ofrece las siguientes ventajas:\n",
    "\n",
    "- ‚úÖ Mejora progresiva del contenido.\n",
    "- ‚úÖ Separa claramente los roles de generaci√≥n, evaluaci√≥n y reescritura.\n",
    "- ‚úÖ Simula un flujo editorial profesional, √∫til en entornos reales de contenido.\n",
    "\n",
    "> üîç **Nota**: Aunque Gemini no tiene una arquitectura expl√≠cita de roles como OpenAI (system/user/assistant), se pueden simular los comportamientos deseados mediante prompts bien dise√±ados y consecutivos.\n",
    "\n",
    "Esta estrategia de *refinamiento iterativo* puede aplicarse en tareas como redacci√≥n, revisi√≥n de c√≥digo, generaci√≥n de ideas, entre otras. üöÄ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc2e23bd-b21c-4f19-8c8e-986b1d41c56b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explicaci√≥n: Los modelos ling√º√≠sticos grandes (LLM) son modelos de redes neuronales profundas entrenados en cantidades masivas de datos de texto. Funcionan prediciendo la siguiente palabra en una secuencia bas√°ndose en los patrones y relaciones aprendidos de los datos de entrenamiento. Esta capacidad predictiva les permite generar texto similar al humano, traducir idiomas, escribir diferentes tipos de contenido creativo y responder a preguntas de manera informativa. Los LLM utilizan una arquitectura transformadora, que les permite procesar y comprender el contexto de largas secuencias de texto mediante mecanismos de atenci√≥n, ponderando la importancia de diferentes partes de la entrada al generar la salida.  A trav√©s del entrenamiento con cantidades masivas de datos, los LLM desarrollan una comprensi√≥n estad√≠stica del lenguaje, lo que les permite realizar una amplia gama de tareas relacionadas con el lenguaje.\n",
      "\n",
      "\n",
      "\n",
      "Retroalimentaci√≥n: La explicaci√≥n proporciona una descripci√≥n decente general de los LLM, pero podr√≠a mejorar en cuanto a claridad, coherencia y atractivo. He aqu√≠ algunos comentarios detallados:\n",
      "\n",
      "* **Claridad:** Si bien la explicaci√≥n es generalmente comprensible, podr√≠a ser m√°s clara para los no expertos. T√©rminos como \"modelos de red neuronal profunda\", \"arquitectura transformadora\" y \"mecanismos de atenci√≥n\" podr√≠an requerir m√°s explicaci√≥n o ejemplos.  Considera la posibilidad de definir brevemente estos t√©rminos o proporcionar analog√≠as para hacerlos m√°s accesibles. Adem√°s, la frase \"comprensi√≥n estad√≠stica del lenguaje\" podr√≠a ser m√°s clara si se ilustra con ejemplos concretos de c√≥mo se manifiesta esta comprensi√≥n.\n",
      "\n",
      "* **Coherencia:** La transici√≥n entre discutir las capacidades predictivas y la arquitectura del transformador podr√≠a ser m√°s fluida.  Hay un ligero salto de *lo que* hacen los LLM a *c√≥mo* lo hacen. Considera la posibilidad de a√±adir una frase de transici√≥n para conectar estas dos ideas. Adem√°s, el √∫ltimo p√°rrafo, que menciona la \"comprensi√≥n estad√≠stica\", podr√≠a integrarse mejor con el resto de la explicaci√≥n. Podr√≠a conectarse de nuevo a la idea de predecir la siguiente palabra o a la arquitectura del transformador.\n",
      "\n",
      "* **Cautivaci√≥n:** La explicaci√≥n es bastante seca y factual. Para hacerla m√°s atractiva, considera la posibilidad de a√±adir un gancho al principio para despertar el inter√©s del lector. Podr√≠a tratarse de un breve ejemplo de lo que pueden hacer los LLM, una pregunta provocadora o una an√©cdota. Tambi√©n podr√≠as a√±adir algunos ejemplos concretos de las tareas que pueden realizar los LLM, o los tipos de datos de texto en los que est√°n entrenados, para hacer la informaci√≥n m√°s tangible y relatable. Finalmente, una frase final que resume el impacto o el potencial futuro de los LLM podr√≠a dejar una impresi√≥n m√°s duradera en el lector.\n",
      "\n",
      "\n",
      "\n",
      "Art√≠culo Final: Los modelos ling√º√≠sticos grandes (LLM) son como cerebros digitales entrenados con una biblioteca masiva de texto, aprendiendo a predecir la siguiente palabra en una secuencia bas√°ndose en los patrones y relaciones que descubren en sus datos de entrenamiento. Esta capacidad predictiva, similar a la forma en que los humanos anticipan las palabras en una conversaci√≥n, les permite realizar tareas notables como generar texto similar al humano, traducir idiomas y responder a preguntas de manera informativa. Para lograr esto, los LLM utilizan una \"arquitectura transformadora\" que, al igual que un lector atento que destaca pasajes importantes, se centra en las partes m√°s relevantes de un texto utilizando \"mecanismos de atenci√≥n\", ponderando esencialmente diferentes palabras en funci√≥n de su importancia contextual. Esta capacidad de centrarse en los aspectos cruciales de una entrada es lo que permite a los LLM procesar y comprender incluso largas secuencias de texto. A trav√©s de este extenso entrenamiento, desarrollan una \"comprensi√≥n estad√≠stica del lenguaje\", lo que significa que no \"entienden\" el lenguaje de la misma manera que los humanos, sino que se vuelven incre√≠blemente h√°biles para predecir qu√© palabras deben seguir a continuaci√≥n, un talento que se traduce en la escritura de diferentes tipos de contenido creativo, la realizaci√≥n de res√∫menes y la participaci√≥n en conversaciones realistas. Este notable avance en el procesamiento del lenguaje natural tiene el potencial de revolucionar la forma en que interactuamos con las m√°quinas y accedemos a la informaci√≥n.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import google.generativeai as genai\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "genai.configure(api_key=os.getenv(\"GEMINI_API_KEY\"))\n",
    "model = genai.GenerativeModel(\"gemini-1.5-pro-latest\")\n",
    "\n",
    "explanation_response = model.generate_content(\n",
    "    \"Explica c√≥mo funcionan los LLM en un solo p√°rrafo.\"\n",
    ")\n",
    "explanation = explanation_response.text\n",
    "print(\"Explicaci√≥n:\", explanation)\n",
    "\n",
    "feedback_prompt = (\n",
    "    \"Eres un editor. Revisa la explicaci√≥n y proporciona comentarios detallados \"\n",
    "    \"sobre claridad, coherencia y cautivaci√≥n (pero no la edites t√∫ mismo):\\n\\n\"\n",
    "    + explanation\n",
    ")\n",
    "feedback_response = model.generate_content(feedback_prompt)\n",
    "feedback = feedback_response.text\n",
    "print(\"\\n\\nRetroalimentaci√≥n:\", feedback)\n",
    "\n",
    "final_prompt = (\n",
    "    \"Revisa el art√≠culo utilizando los siguientes comentarios, pero mantenlo a un solo p√°rrafo.\"\n",
    "    f\"\\nExplicaci√≥n:\\n{explanation}\\n\\nComentarios:\\n{feedback}\"\n",
    ")\n",
    "final_response = model.generate_content(final_prompt)\n",
    "final_article = final_response.text\n",
    "print(\"\\n\\nArt√≠culo Final:\", final_article)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
