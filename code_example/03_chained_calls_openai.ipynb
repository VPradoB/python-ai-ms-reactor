{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fd921d4-c645-480c-b319-ad0c32344a79",
   "metadata": {},
   "source": [
    "# Llamadas encandenadas con OpenAI\n",
    "\n",
    "A continuación, un flujo dividido en 3 pasos usando la API de OpenAI:\n",
    "\n",
    "1. **Generación inicial del contenido**  \n",
    "   Se le pide al modelo una explicación simple de cómo funcionan los LLMs.\n",
    "\n",
    "2. **Evaluación del contenido**  \n",
    "   Se le solicita al modelo que actúe como un editor profesional y proporcione retroalimentación sobre claridad, coherencia y nivel de cautivación del texto.\n",
    "\n",
    "3. **Revisión final del contenido**  \n",
    "   El modelo ahora usa la retroalimentación generada anteriormente para reescribir el contenido original, manteniéndolo en un solo párrafo pero mejorando su calidad.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e407022-f0e5-4352-b3c8-38a5a5d45aae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explicación:  Los Modelos de Lenguaje Extensos (LLMs, por sus siglas en inglés) son sistemas de inteligencia artificial entrenados en grandes cantidades de texto para predecir la próxima palabra en una secuencia, lo que les permite generar texto coherente y contextualizado. Utilizan arquitecturas como los transformadores, que emplean mecanismos de atención para analizar relaciones entre palabras en un contexto dado, capturando patrones, significados y estructuras del lenguaje. Durante el entrenamiento, ajustan miles de millones de parámetros mediante el procesamiento de datos masivos, aprendiendo reglas gramaticales, conceptos semánticos y asociaciones. Una vez entrenados, los LLM generan respuestas basadas en las entradas del usuario, adaptándose al contexto y aplicando el conocimiento aprendido, aunque no \"comprendan\" como lo haría un humano, sino que operan estadísticamente para producir resultados plausibles.\n",
      "\n",
      "\n",
      "Retroalimentación:  Tu explicación sobre los Modelos de Lenguaje Extensos (LLMs) es sólida y técnicamente precisa, pero presenta algunas áreas que podrían beneficiarse de ajustes en términos de claridad, coherencia y cautivación. A continuación, te proporciono un análisis detallado:\n",
      "\n",
      "### **1. Claridad**\n",
      "- **Fortalezas**: \n",
      "  - La explicación utiliza un lenguaje técnico apropiado y bien fundamentado, lo que demuestra un buen entendimiento del tema.\n",
      "  - Los conceptos clave, como \"transformadores\", \"mecanismos de atención\" y \"parámetros\", están correctamente mencionados y alineados con el funcionamiento real de los LLMs.\n",
      "  \n",
      "- **Áreas de mejora**:\n",
      "  - Algunos términos, como \"transformadores\" y \"mecanismos de atención\", pueden no ser claros para audiencias no técnicas. Aunque están correctamente utilizados, sería útil agregar una breve explicación de qué son o cómo funcionan en términos simples.\n",
      "  - La frase \"operan estadísticamente para producir resultados plausibles\" puede generar confusión si el lector no está familiarizado con lo que significa \"estadísticamente\" en este contexto. Una mejor opción sería especificar que los modelos generan resultados basados en probabilidades calculadas a partir de patrones aprendidos.\n",
      "\n",
      "### **2. Coherencia**\n",
      "- **Fortalezas**:\n",
      "  - El texto mantiene un flujo lógico al explicar primero qué son los LLMs, cómo funcionan, cómo se entrenan y finalmente cómo generan respuestas.\n",
      "  - Los conceptos están relacionados de manera estructurada, lo que facilita seguir el hilo del argumento.\n",
      "\n",
      "- **Áreas de mejora**:\n",
      "  - Hay un ligero salto conceptual entre la explicación del entrenamiento y la afirmación de que los modelos no \"comprenden como un humano\". Este punto podría conectarse mejor, explicando primero que el aprendizaje de los LLMs es basado en patrones estadísticos y luego contrastando esto con la ausencia de comprensión humana.\n",
      "  - La frase \"capturando patrones, significados y estructuras del lenguaje\" mezcla conceptos (gramática, semántica, etc.) sin aclarar cómo se diferencian o interactúan. Esto podría ser más explícito para evitar ambigüedades.\n",
      "\n",
      "### **3. Cautivación**\n",
      "- **Fortalezas**:\n",
      "  - La mención de términos avanzados como \"mecanismos de atención\" y \"parámetros\" puede captar la atención de lectores familiarizados con el tema.\n",
      "  - El contraste entre cómo los LLMs generan resultados y la falta de comprensión humana es interesante y podría ser cautivador si se desarrolla más.\n",
      "\n",
      "- **Áreas de mejora**:\n",
      "  - El tono es muy técnico y neutro, lo que puede volverlo menos atractivo para una audiencia general. Podrías incluir ejemplos concretos o comparaciones para ilustrar cómo los LLMs funcionan en la práctica, por ejemplo, explicando cómo completan una oración o generan un artículo.\n",
      "  - Una frase de apertura más llamativa podría captar mejor la atención del lector. Algo como: “¿Cómo es que una máquina puede escribir poesía, responder preguntas o incluso entablar conversaciones complejas? Los Modelos de Lenguaje Extensos (LLMs) lo hacen posible”.\n",
      "\n",
      "### **Conclusión**\n",
      "Tu explicación es precisa y bien estructurada, pero podría beneficiarse de un enfoque más accesible y cautivador para una audiencia más amplia. Considera incluir ejemplos prácticos, simplificar algunos términos técnicos y mejorar la conexión entre ideas para hacer el texto más claro y atractivo. ¡Buen trabajo en general!\n",
      "\n",
      "\n",
      "Final Article:  Los Modelos de Lenguaje Extensos (LLMs, por sus siglas en inglés) son sistemas de inteligencia artificial que, mediante arquitecturas avanzadas como los transformadores y el uso de mecanismos de atención, analizan relaciones entre palabras para predecir la próxima en una secuencia, generando texto coherente y contextualizado basado en patrones probabilísticos aprendidos. Entrenados con grandes cantidades de datos textuales, ajustan miles de millones de parámetros para captar estructuras gramaticales, significados semánticos y asociaciones complejas del lenguaje, lo que les permite adaptarse al contexto de las entradas del usuario y producir respuestas plausibles. Aunque no comprenden como lo haría un humano, operan identificando patrones y relaciones estadísticas, lo que los hace capaces de realizar tareas como redactar textos, responder preguntas o incluso mantener conversaciones complejas, destacándose como herramientas poderosas en aplicaciones prácticas.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "client = openai.OpenAI(base_url=\"https://models.inference.ai.azure.com\", api_key=os.getenv(\"GITHUB_API_KEY\"))\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    temperature=0.7,\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Explica cómo funcionan los LLM en un solo párrafo.\"}],\n",
    ")\n",
    "\n",
    "explanation = response.choices[0].message.content\n",
    "print(\"Explicación: \", explanation)\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    temperature=0.7,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": (\n",
    "                \"Eres un editor. Revisa la explicación y proporciona comentarios detallados sobre claridad, coherencia \"\n",
    "                \"y cautivación (pero no la edites tú mismo):\\n\\n\"\n",
    "            )\n",
    "            + explanation,\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "\n",
    "feedback = response.choices[0].message.content\n",
    "print(\"\\n\\nRetroalimentación: \", feedback)\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    temperature=0.7,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": (\n",
    "                \"Revisa el artículo utilizando los siguientes comentarios, pero mantenlo a un solo párrafo.\"\n",
    "                f\"\\nExplicación:\\n{explanation}\\n\\nComentarios:\\n{feedback}\"\n",
    "            ),\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "\n",
    "final_article = response.choices[0].message.content\n",
    "print(\"\\n\\nFinal Article: \", final_article)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
